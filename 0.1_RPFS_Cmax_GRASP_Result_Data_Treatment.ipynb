{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RPFS GRASP (Cmax objective) - Data treatment of result files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os, fnmatch\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning)\n",
    "import glob\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "if sys.version_info[0] < 3: \n",
    "    from StringIO import StringIO\n",
    "else:\n",
    "    from io import StringIO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List files in the output folder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rootfolder = os.getcwd()\n",
    "file_list = []\n",
    "for path in glob.glob(os.path.join(rootfolder, os.path.join('..', 'pfsp_experiments', 'run_grasp_rpfs_cmax_global', '*.csv'))):\n",
    "    if 'parametrization' not in path:\n",
    "        file_list.append(path)\n",
    "file_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process all CSV files and append all data to a single dataframe"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for path in Path(os.path.join(rootfolder, 'output')).rglob('*.csv'):\n",
    "    cmd = \"sed -e :1 -e 's/\\(\\[[^]]*\\),/\\1;/g' -e t1 < {} > {}\".format(path.as_posix(), '*'+path.as_posix())\n",
    "    print(cmd)\n",
    "    #os.system(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative script to treat files with incorrect number of coluns or faulty lines\n",
    "def alternative_csv_reader(filename, delimiter, header, names):\n",
    "    with open(filename, 'r') as file:\n",
    "        lines = file.readlines() \n",
    "        count = 1\n",
    "        line_list = []\n",
    "        num_columns = len(names)\n",
    "        for line in lines:  # Strips the newline character \n",
    "            #print(\"line{}: {}\".format(count, line.strip())) \n",
    "            nc = len(line.split(','))\n",
    "            if 'execution_id,' in line:\n",
    "                #num_columns = nc\n",
    "                print('Detected {0} columns in CSV file.'.format(nc))\n",
    "            else:\n",
    "                if not names[0] in line:\n",
    "                    if nc == num_columns:\n",
    "                        line_list.append(line)\n",
    "                    elif nc > num_columns:  # treat strange truncated lines\n",
    "                        line = line[line.rfind('2020_'):]\n",
    "                        nc = len(line.split(','))\n",
    "                        if nc == num_columns:\n",
    "                            print('WARN: truncating line {0}, for having more columns than expected.'.format(count))\n",
    "                            line_list.append(line)\n",
    "                        else:\n",
    "                            print('WARN: Ignoring line {0}, since it has {1} columns, instead of {2}: '.format(count, nc, num_columns), line)\n",
    "                    else:  # Ignore line\n",
    "                        print('WARN: Ignoring line {0}: '.format(count), line)    \n",
    "                elif len(line_list) > 0 and len(line_list[-1].split(',')) < num_columns:  # current line is a continuation of the previous one\n",
    "                    line_list[-1] = line_list[-1].replace('\\n', '') + line\n",
    "                    print('*** Treated line {0}: '.format(count), line_list[-1])\n",
    "                else:  # Ignore line\n",
    "                    print('WARN: Ignoring line {0}: '.format(count), line)\n",
    "            count += 1\n",
    "        # assert all lines have the same number of columns\n",
    "        count = 1\n",
    "        for line in line_list:\n",
    "            nc = len(line.split(','))\n",
    "            if nc != num_columns:\n",
    "                print('ERROR: Line {0} has {1} columns, instead of {2}: '.format(count, nc, num_columns), line)\n",
    "            count += 1\n",
    "        text_data = StringIO(''.join(line_list))\n",
    "        #print('line_list: ', str(line_list))\n",
    "        #print('text_data: ', text_data)\n",
    "        df = pd.read_csv(text_data, delimiter=delimiter, header=header, names=names)\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df = pd.DataFrame()\n",
    "for filename in file_list:\n",
    "    print('Processing file ', filename)\n",
    "    try:\n",
    "        df_ = pd.read_csv(filename, delimiter=',', header=0, names=['batch_id', 'run_id', 'execution_id', 'seed', 'ub_name', 'instance_name', 'alpha', 'n', 'm', 'budget_T', 'time_spent', 'exit_code', 'solution_value', 'permutation', 'time_spent_2', 'time_to_best_sol', 'iterations', 'num_visited_solutions', 'num_improvements', 'first_improvement', 'vnd_size', 'vnd_permutation', 'random_vnd', 'adaptive', 'const_beta1', 'const_beta2', 'time_factor'])\n",
    "    except:  # try alternative method to read csv lines\n",
    "        df_ = alternative_csv_reader(filename, delimiter=',', header=0, names=['batch_id', 'run_id', 'execution_id', 'seed', 'ub_name', 'instance_name', 'alpha', 'n', 'm', 'budget_T', 'time_spent', 'exit_code', 'solution_value', 'permutation', 'time_spent_2', 'time_to_best_sol', 'iterations', 'num_visited_solutions', 'num_improvements', 'first_improvement', 'vnd_size', 'vnd_permutation', 'random_vnd', 'adaptive', 'const_beta1', 'const_beta2', 'time_factor'])\n",
    "    df_['budget_T'] = df_['budget_T'].astype(str).apply(lambda x: x.strip())\n",
    "    df_['multibudget'] = df_['budget_T'].apply(lambda x: 1 if ' ' in x else 0)\n",
    "    df_t = df_[df_['multibudget'] == 1]\n",
    "    if len(df_t.index) > 0:\n",
    "        print('WARN: invalid budget values detected')\n",
    "        print(df_t)\n",
    "    df = df.append(df_.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = df\n",
    "df_all.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove trailing spaces on column names "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = df_all.rename(columns=lambda x: x.strip())\n",
    "df_all.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trim existing string columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trim_all_columns(df):\n",
    "    \"\"\"\n",
    "    Trim whitespace from ends of each value across all series in dataframe\n",
    "    \"\"\"\n",
    "    trim_strings = lambda x: x.strip() if isinstance(x, str) else x\n",
    "    return df.applymap(trim_strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = trim_all_columns(df_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove duplicated headers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_all = df_all[(df_all['n'] != 'n')]\n",
    "display(df_all['n'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert column types from object "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_column_types(df):\n",
    "    for col in df.columns:\n",
    "        if col in ['seed','n','m','time_spent','exit_code','solution_value','time_spent_2','time_to_best_sol','iterations','num_visited_solutions','num_improvements','vnd_size','const_beta1','const_beta2','time_factor']:\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "        elif col in ['first_improvement','random_vnd', 'adaptive']:\n",
    "            df[col] = df[col].astype('bool')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df_all = convert_column_types(df_all)\n",
    "df_all.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Include a new column with the instance set name "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['instance_type'] = df_all['instance_name'].apply(lambda x: 'tail' if ('tail' in x) else 'ying')\n",
    "df_all['instance_type'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modify the `instance_name` column to remove the file path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['instance_name'] = df_all['instance_name'].apply(lambda st: st[st.rfind(\"/\")+1:])\n",
    "df_all['instance_name'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fix the values in column budget_Gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all[\"budget_T\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new data frame with split value columns\n",
    "new = df_all[\"budget_T\"].str.split(\" \", n = 2, expand = True) \n",
    "# making separate first name column from new data frame \n",
    "df_all[\"Gamma\"]= new[0] \n",
    "# convert Gamma columns to numeric\n",
    "df_all[\"Gamma\"] = pd.to_numeric(df_all[\"Gamma\"], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all[\"Gamma\"].unique()\n",
    "df_all['Gamma%'] = df_all['Gamma']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adjust n_str, alpha and seq values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['n_str'] = df_all['n'].astype(str).str.zfill(3)\n",
    "df_all['instance_name_short'] = df_all['instance_name'].apply(lambda x: x[:x.find('_cmax_inputs')] if '_cmax_inputs' in x else x[:x.find('.txt')])\n",
    "df_all.loc[(df_all['instance_type'] == 'tail'), 'seq'] = df_all.loc[(df_all['instance_type'] == 'tail'), 'instance_name'].apply(lambda x: x[x.find('tail')+len('tail'):x.find('_')] if '_' in x else x[x.find('tail')+len('tail'):x.find('.')])\n",
    "df_all.loc[(df_all['instance_type'] == 'ying'), 'seq'] = df_all.loc[(df_all['instance_type'] == 'ying'), 'instance_name'].apply(lambda x: x[x.find('_')-2:x.find('_')] if '_cmax_inputs' in x else x[x.find('.')-2:x.find('.')])\n",
    "\n",
    "df_all['alpha_str'] = df_all['instance_name_short'].apply(lambda x: x[x.rfind('_')+1:] if '_' in x else 'na')\n",
    "df_all.loc[(df_all['alpha_str'] == 'na'), 'alpha_str'] = df_all.loc[(df_all['alpha_str'] == 'na'), 'alpha'].astype(str)\n",
    "df_all['alpha_str'] = df_all['alpha_str'].apply(lambda x: x.replace('%', ''))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['alpha_str'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['seq'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['instance_name_short'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Round columns containing time (in seconds) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['time_spent'] = df_all['time_spent'].round(2)\n",
    "df_all['time_spent_2'] = df_all['time_spent_2'].round(2)\n",
    "df_all['time_to_best_sol'] = df_all['time_to_best_sol'].round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for execution errors \n",
    "\n",
    "Exit code != 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_all.copy()\n",
    "display(df[(df['exit_code'] != 0)]['solution_value'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove rows with execution errors (exit_code != 0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display('Exit codes: ', df[(df['exit_code'] != 0)]['exit_code'].unique())\n",
    "df = df[(df['exit_code'] == 0)]\n",
    "display('Exit codes: ', df['exit_code'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sort data according to instance_type, instance_name, alpha, n, m, Gamma and set index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Sorting dataset...')\n",
    "df = df.sort_values(['instance_type', 'n', 'm', 'alpha_str', 'instance_name', 'Gamma'])\n",
    "display(df.dtypes)\n",
    "df = df.set_index(['instance_type', 'n', 'm', 'alpha_str', 'instance_name', 'Gamma'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df.head(6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find missing results, for a given instance and a given value of Gamma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a given instance_name and budget_Gamma, there should be 100 results.\n",
    "\n",
    "First we will build a dataframe with the instances list and all required budget values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma_range = np.array(range(0, 101))[0:101:5]\n",
    "gamma_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "filename_list = df.reset_index()['instance_name'].unique()\n",
    "for instance_name in filename_list:\n",
    "    \n",
    "    if '_cmax_inputs' in instance_name:\n",
    "        instance_name_short = instance_name[:instance_name.find('_cmax_inputs')]\n",
    "    else:\n",
    "        instance_name_short = instance_name[:instance_name.find('.txt')]\n",
    "    # end if\n",
    "    if '_' in instance_name:\n",
    "        alpha = instance_name_short[instance_name_short.rfind('_')+1:].replace('%', '').strip()\n",
    "    else:\n",
    "        alpha = instance_name_short[5:7].strip()  # RB1501001.txt\n",
    "    # end if\n",
    "    #print('alpha: {}'.format(alpha))\n",
    "    for gamma in gamma_range:\n",
    "        data.append([instance_name.strip(), gamma])\n",
    "df_instances = pd.DataFrame(data, columns=['instance_name', 'Gamma'])\n",
    "#df_instances = df_instances.set_index(['instance_name'])\n",
    "display(df_instances)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, lets join the instances dataframe with the results one (left join)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_joined = df_instances.merge(df.reset_index(), how='left', left_on=['instance_name', 'Gamma'], right_on=['instance_name', 'Gamma'])\n",
    "df_joined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grouped = df.groupby(['instance_type', 'instance_name', 'alpha_str', 'n', 'm', 'Gamma']).agg({'execution_id' : ['count']}).reset_index()\n",
    "df_grouped.columns = [ '_'.join(str(i) for i in col) for col in df_grouped.columns]\n",
    "#df_grouped.reset_index(inplace=True)\n",
    "df_grouped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**For a given instance_name and budget_Gamma, there should be 100 results.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perc_list = gamma_range\n",
    "df_ = df.reset_index()\n",
    "table = pd.pivot_table(df_[(df_['Gamma'].isin(perc_list))], values='execution_id', index=['instance_type', 'alpha_str', 'n', 'm', 'seq'], columns=['Gamma'], aggfunc='count', fill_value=0)\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None): \n",
    "    display(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export missing results\n",
    "\n",
    "Now we will export to CSV a list with all rows with NaN values (missing experimental results)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_df = df_grouped[df_grouped['execution_id_count'] < 100]\n",
    "missing_df['tail_prefix'] = missing_df['instance_name_'].str.find('_')\n",
    "#missing_df['tail_number'] = missing_df['instance_name_'].str[4:7]\n",
    "#missing_df['tail_number'] = pd.to_numeric(missing_df['tail_number'], errors='coerce')\n",
    "missing_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_df['instance_name_'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_df = missing_df[(missing_df['tail_prefix'] <= 7) | (missing_df['instance_name_'].str.find('tail0100') >= 0)]\n",
    "print('Saving file on folder: ' + rootfolder)\n",
    "fname = os.path.join(os.getcwd(), 'GRASP_Cmax_missing_results.csv')\n",
    "missing_df.to_csv(fname, sep=';')\n",
    "print('Saved: ' + fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = pd.pivot_table(df, values='execution_id', index=['instance_name', 'alpha', 'n'], columns=['Gamma'], aggfunc='count', fill_value=0)\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None): \n",
    "    display(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export the dataset to CSV file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "outputfolder = os.path.join(os.getcwd(), 'results', 'consolidated')\n",
    "print('Saving file on folder: ' + outputfolder)\n",
    "fname = os.path.join(outputfolder, 'RPFS_Cmax_GRASP_all_results.csv.gz')\n",
    "df.to_csv(fname, sep=';')\n",
    "print('Saved: ' + fname)\n",
    "fname = os.path.join(outputfolder, 'RPFS_Cmax_GRASP_all_results.pkl.gz')\n",
    "df.to_pickle(fname)\n",
    "print('Saved: ' + fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index().info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-rccp_cronos] *",
   "language": "python",
   "name": "conda-env-.conda-rccp_cronos-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
