{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RPFS C&CG (Cmax objective) - Data treatment of result files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os, fnmatch\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning)\n",
    "import glob\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "if sys.version_info[0] < 3: \n",
    "    from StringIO import StringIO\n",
    "else:\n",
    "    from io import StringIO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List files in the output folder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rootfolder = os.path.join('..', 'pfsp_experiments', 'run_ccg_rpfs_cmax_global')\n",
    "file_list = glob.glob(os.path.join(rootfolder, '*.csv'), recursive=True)\n",
    "file_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read all the CSV files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative script to treat files with incorrect number of coluns or faulty lines\n",
    "def alternative_csv_reader(filename, delimiter=',', header=0, names=None):\n",
    "    with open(filename, 'r') as file:\n",
    "        lines = file.readlines() \n",
    "        count = 1\n",
    "        line_list = []\n",
    "        num_columns = 23\n",
    "        for line_num, line in enumerate(lines):  # Strips the newline character \n",
    "            #print(\"line{}: {}\".format(count, line.strip())) \n",
    "            nc = len(line.split(','))\n",
    "            if 'executionId,' in line:\n",
    "                #num_columns = nc\n",
    "                if nc == num_columns - 1 and line_num == 0:\n",
    "                    line_list.append(line.replace('\\n', '') + ',cut_count\\n')\n",
    "                # end if\n",
    "                print('Detected {0} columns in CSV file.'.format(nc))\n",
    "            else:\n",
    "                if 'none,' in line:\n",
    "                    if nc == num_columns - 1:\n",
    "                        line_list.append(line.replace('\\n', '') + ',\\n')\n",
    "                    elif nc == num_columns:\n",
    "                        line_list.append(line)\n",
    "                    elif nc > num_columns:  # treat strange truncated lines\n",
    "                        line = line[line.rfind('none,'):]\n",
    "                        nc = len(line.split(','))\n",
    "                        #if nc >= num_columns:\n",
    "                        #    print('WARN: truncating line {0}, for having more columns than expected.'.format(count))\n",
    "                        #    line_list.append(line)\n",
    "                        #else:\n",
    "                        print('WARN: Ignoring line {0}, since it has {1} columns, instead of {2}: '.format(count, nc, num_columns), line)\n",
    "                    else:  # Ignore line\n",
    "                        print('WARN: Ignoring line {0}: '.format(count), line)  \n",
    "                else:  # Ignore line\n",
    "                    print('WARN: Ignoring line {0}: '.format(count), line)\n",
    "            count += 1\n",
    "        # assert all lines have the same number of columns\n",
    "        count = 1\n",
    "        for line in line_list:\n",
    "            nc = len(line.split(','))\n",
    "            if nc < num_columns:\n",
    "                print('ERROR: Line {0} has {1} columns, instead of {2}: '.format(count, nc, num_columns), line)\n",
    "            count += 1\n",
    "        text_data = StringIO(''.join(line_list))\n",
    "        #print('line_list: ', str(line_list))\n",
    "        #print('text_data: ', text_data)\n",
    "        df = pd.read_csv(text_data, delimiter=delimiter, header=header, names=names)\n",
    "        return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process all CSV files and append all data to a single dataframe (one per solution method: Wilson, Wagner) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "dfdict = dict()\n",
    "for filepath in file_list:\n",
    "    print('Processing file ', filepath)\n",
    "    try:\n",
    "        df_ = pd.read_csv(filepath, delimiter=',', header=0, names=['executionId','ub_name','instance_name','alpha','n','m','budget_Gamma','Gamma_abs','cmax','permutation','time_spent','time_to_best_sol','mp_total_time','sp_total_time','iterations','num_visited_solutions','num_improvements','is_optimal','validated','gap','lb','cost','cmax_validation','cut_count'])\n",
    "    except:  # try alternative method to read csv lines\n",
    "        df_ = alternative_csv_reader(filepath, delimiter=',', header=0, names=['executionId','ub_name','instance_name','alpha','n','m','budget_Gamma','Gamma_abs','cmax','permutation','time_spent','time_to_best_sol','mp_total_time','sp_total_time','iterations','num_visited_solutions','num_improvements','is_optimal','validated','gap','lb','cost','cmax_validation','cut_count'])\n",
    "    filename = filepath[filepath.rfind(os.path.sep)+1:]\n",
    "    if 'gamma' in filename or 'partialresults' in filename:  # skip result files with partial results\n",
    "        continue\n",
    "    if filename.find('_instance') > 0:\n",
    "        modelname = filename[len('separation_cmax_'):filename.find('_instance')]\n",
    "    else:\n",
    "        if filename.find('_ying') > 0:\n",
    "            modelname = filename[len('separation_cmax_'):filename.find('_ying')]\n",
    "        elif filename.find('_tail') > 0:\n",
    "            modelname = filename[len('separation_cmax_'):filename.find('_tail')]\n",
    "        else:\n",
    "            continue\n",
    "    print('Read results for model ' + modelname)\n",
    "    if modelname in dfdict:\n",
    "        dfdict[modelname] = pd.concat([dfdict[modelname], df_])\n",
    "    else:\n",
    "        dfdict[modelname] = df_.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfdict['wilson'].info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove duplicated header rows from both dataframes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_invalid_values(df):\n",
    "    all_invalid_values = set()\n",
    "    for col in df:\n",
    "        if col not in ['executionId','ub_name','instance_name','budget_Gamma','permutation','is_optimal','validated']:\n",
    "            # 'alpha','n','m','cmax','time_spent','time_to_best_sol','iterations','num_visited_solutions','num_improvements','gap','lb','cost','cmax_dp'\n",
    "            a = pd.to_numeric(df[col], errors='coerce')\n",
    "            idx = a.isna()\n",
    "            invalid_values = df.loc[idx][col].unique()\n",
    "            all_invalid_values.update(invalid_values)\n",
    "        #elif col in ['is_optimal','validated']\n",
    "    print('Invalid values:', all_invalid_values)\n",
    "    return all_invalid_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, df in dfdict.items():\n",
    "    dfdict[key] = df[(df['executionId'] != 'executionId')]\n",
    "    print(key, dfdict[key].dtypes)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def filter_invalid_values(df):\n",
    "    # IMPORTANT: AVOID FILTERING 'NAN' VALUES\n",
    "    for invalid_value in find_invalid_values(df):\n",
    "        if isinstance(invalid_value, str):  # Evita filtrar os nan\n",
    "            df = df[~(df == invalid_value).any(axis=1)]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for key, df in dfdict.items():\n",
    "    print(df.info())\n",
    "    df.replace('Inf', 'nan', inplace=True)\n",
    "    df = filter_invalid_values(df)\n",
    "    find_invalid_values(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert column types from object "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_column_types(df):\n",
    "    for col in df:\n",
    "        if col in ['alpha','n','m','cmax','budget_Gamma','Gamma_abs','time_spent','time_to_best_sol','iterations','num_visited_solutions','num_improvements','gap','lb','cost','cmax_validation', 'mp_total_time', 'sp_total_time', 'seq']:\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "        elif col in ['is_optimal','validated']:\n",
    "            df[col] = df[col].astype('bool')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for key, df in dfdict.items():\n",
    "    dfdict[key] = convert_column_types(df)\n",
    "    print(key, dfdict[key].dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trim existing string columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trim_all_columns(df):\n",
    "    \"\"\"\n",
    "    Trim whitespace from ends of each value across all series in dataframe\n",
    "    \"\"\"\n",
    "    trim_strings = lambda x: x.strip() if isinstance(x, str) else x\n",
    "    return df.applymap(trim_strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, df in dfdict.items():\n",
    "    dfdict[key] = trim_all_columns(df)\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Include a column with the name of the underlying C&CG MILP Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, df in dfdict.items():\n",
    "    dfdict[key]['model'] = key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Include a column with the name of the instance type (ying or tail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, df in dfdict.items():\n",
    "    print(key, df)\n",
    "    dfdict[key]['instance_type'] = df['instance_name'].apply(lambda x: 'tail' if ('tail' in x) else 'ying')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Include a column with the budget parameter value in %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, df in dfdict.items():\n",
    "    dfdict[key]['Gamma%'] = df['budget_Gamma']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenate dataframes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat(list(dfdict.values()))\n",
    "df.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for duplicated values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.duplicated()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fix instance names \n",
    "\n",
    "The original instance names, in the instance file zip, were assembled incorrectly.\n",
    "\n",
    "The problem lies in the alpha percentage. We are now going to fix this issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['n_str'] = df['n'].astype(str).str.zfill(3)\n",
    "df['instance_name_short'] = df['instance_name'].apply(lambda x: x[:x.find('_cmax_inputs')] if '_cmax_inputs' in x else x[:x.find('.txt')])\n",
    "df.loc[(df['instance_type'] == 'tail'), 'seq'] = df.loc[(df['instance_type'] == 'tail'), 'instance_name'].apply(lambda x: x[x.find('tail')+len('tail'):x.find('_')] if '_cmax_inputs' in x else x[x.find('tail')+len('tail'):x.find('.')])\n",
    "df.loc[(df['instance_type'] == 'ying'), 'seq'] = df.loc[(df['instance_type'] == 'ying'), 'instance_name'].apply(lambda x: x[x.find('_')-2:x.find('_')] if '_cmax_inputs' in x else x[x.find('.')-2:x.find('.')])\n",
    "#df['alpha_str'].loc[(df['m'] == 2)] = df.loc[(df['m'] == 2), 'instance_name'].apply(lambda x: x[x.rfind('_')+1:] if '_cmax_inputs' in x else x)\n",
    "df['alpha_str'] = df['instance_name_short'].apply(lambda x: x[x.rfind('_')+1:] if '_' in x else 'na')\n",
    "df.loc[(df['alpha_str'] == 'na'), 'alpha_str'] = df.loc[(df['alpha_str'] == 'na'), 'alpha'].astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['alpha_str'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['n_str'].unique()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df.to_excel('rpfs_cmax_ccg_treated_results.xlsx')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df['instance_name'] = 'RB' + df['n_str'] + df['alpha_str'] + df['seq'] + '_' + df['instance_name'].apply(lambda x: x[x.find('_')+1:])\n",
    "df.drop(columns=['n_str', 'alpha_str'], inplace=True)\n",
    "df.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Round columns containing time (in seconds) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['time_spent'] = df['time_spent'].round(2)\n",
    "df['time_to_best_sol'] = df['time_to_best_sol'].round(2)\n",
    "df['mp_total_time'] = df['mp_total_time'].round(2)\n",
    "df['sp_total_time'] = df['sp_total_time'].round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop duplicate rows, preserving the newest (last) ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_columns = ['model', 'n', 'm', 'alpha_str', 'seq', 'budget_Gamma', 'Gamma_abs', 'instance_type', 'instance_name']\n",
    "df[df.duplicated(subset=key_columns)].sort_values(by=key_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(subset=key_columns, keep='last', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sort data according to model, instance_name, alpha, n, m and Gamma and set index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Sorting dataset...')\n",
    "df = df.sort_values(key_columns)\n",
    "display(df.dtypes)\n",
    "df = df.set_index(key_columns, verify_integrity=True)\n",
    "display(df.head(6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find missing results, for a given value of alpha, n and m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a given group of alpha, n, m and budget_Gamma, there should be 10 results.\n",
    "\n",
    "First we will build a dataframe with the instances list and all required budget values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma_range = np.array(range(0, 101))[0:101:5]\n",
    "gamma_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list1 = list(Path(os.path.join(rootfolder, 'instances', 'robust', 'ying', 'rob-pfsp-cmax')).rglob('*.txt'))\n",
    "file_list2 = list(Path(os.path.join(rootfolder, 'instances', 'robust', 'taillard', 'rob-pfsp-cmax')).rglob('*.txt'))\n",
    "file_list = file_list1 + file_list2\n",
    "file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "rootfolder = os.getcwd()\n",
    "file_set = set()\n",
    "for path in file_list:\n",
    "    instance_path = path.name\n",
    "    #print('instance_path: ' + instance_path)    \n",
    "    if '.txt' not in instance_path:\n",
    "        continue\n",
    "    if 'tail' in instance_path:\n",
    "        if instance_path[:instance_path.find('_')] not in ['tail001', 'tail002', 'tail003', 'tail004', 'tail005', 'tail006', 'tail007', 'tail008', 'tail009', 'tail010']:\n",
    "            #print(instance_path[:instance_path.find('_')])\n",
    "            continue\n",
    "    instance_name = instance_path[instance_path.rfind(os.path.sep)+1:]\n",
    "    file_set.add(instance_name)\n",
    "#print(file_set, file_set)\n",
    "for instance_name in file_set:\n",
    "    #print('instance_name: ' + instance_name)\n",
    "    seq = instance_name[instance_name.find('_')-2:instance_name.find('_')]\n",
    "    info = instance_name[instance_name.find('_')+1:]\n",
    "    n = info[:info.find('_')]\n",
    "    info = info[info.find('_')+1:]\n",
    "    m = info[:info.find('_')]\n",
    "    info = info[info.find('_')+1:]\n",
    "    alpha = info[:info.find('_')]\n",
    "    \n",
    "    if '_cmax_inputs' in instance_name:\n",
    "        instance_name_short = instance_name[:instance_name.find('_cmax_inputs')]\n",
    "    else:\n",
    "        instance_name_short = instance_name[:instance_name.find('.txt')]\n",
    "    # end if\n",
    "    if '_' in instance_name:\n",
    "        alpha = instance_name_short[instance_name_short.rfind('_')+1:]\n",
    "    else:\n",
    "        alpha = instance_name_short[5:7]  # RB1501001.txt\n",
    "    # end if\n",
    "    \n",
    "    instance_type = 'ying'\n",
    "    if 'tail' in instance_name:\n",
    "        instance_type = 'tail'\n",
    "    else:\n",
    "        if int(n) > 20:\n",
    "            continue\n",
    "    for gamma in gamma_range:\n",
    "        budget_gamma = (gamma * (int(m) * int(n)) / 100.0)\n",
    "        for model in list(dfdict.keys()):\n",
    "            data.append([model, seq, alpha, int(n), int(m), budget_gamma, gamma, instance_type, instance_name])\n",
    "df_instances = pd.DataFrame(data, columns=['model', 'seq', 'alpha_str', 'n', 'm', 'budget_Gamma', 'Gamma_abs', 'instance_type', 'instance_name'])\n",
    "for col in df_instances:\n",
    "    if col in ['n','m','budget_Gamma','Gamma_abs']:\n",
    "        df_instances[col] = pd.to_numeric(df_instances[col], errors='coerce')\n",
    "display(df_instances.dtypes)\n",
    "df_instances = df_instances.set_index(['model', 'n', 'm', 'alpha_str', 'seq', 'budget_Gamma', 'Gamma_abs', 'instance_type', 'instance_name'], verify_integrity=True)\n",
    "display(df_instances)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ = df_instances.reset_index()\n",
    "df_[df_['alpha_str'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_instances.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, lets join the instances dataframe with the results one (left join)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_joined = df_instances.join(df, how='left')\n",
    "df_joined"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df_joined.reset_index()[['model', 'n', 'm', 'alpha', 'seq', 'budget_Gamma', 'Gamma_abs', 'instance_type']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will export to CSV a list with all rows with NaN values (missing experimental results)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_df = df_joined[df_joined[['cmax']].isnull().any(axis=1)].reset_index()[['model', 'n', 'm', 'alpha_str', 'seq', 'budget_Gamma', 'Gamma_abs', 'instance_type', 'instance_name']]\n",
    "outputfolder = os.path.join(os.getcwd(), 'results', 'consolidated')\n",
    "if not os.path.exists(outputfolder):\n",
    "    os.makedirs(outputfolder)\n",
    "print('Saving file on folder: ' + outputfolder)\n",
    "fname = os.path.join(outputfolder, 'RPFS_cmax_missing_results.xlsx')\n",
    "missing_df.to_excel(fname)\n",
    "print('Saved: ' + fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grouped = df.groupby(['alpha', 'n', 'm', 'Gamma%']).agg({'executionId' : ['count']}).reset_index()\n",
    "df_grouped.columns = [ ' '.join(str(i) for i in col) for col in df_grouped.columns]\n",
    "#df_grouped.reset_index(inplace=True)\n",
    "df_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perc_list = gamma_range\n",
    "table = pd.pivot_table(df[(df['Gamma%'].isin(perc_list))], values='executionId', index=['instance_type', 'alpha_str', 'n', 'm', 'model'], columns=['Gamma%'], aggfunc='count', fill_value=0)\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None): \n",
    "    display(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export the dataset to CSV file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "outputfolder = os.path.join(os.getcwd(), 'results', 'consolidated')\n",
    "print('Saving file on folder: ' + outputfolder)\n",
    "fname = os.path.join(outputfolder, 'RPFS_Cmax_CCG_all_results.csv')\n",
    "df.to_csv(fname, sep=';')\n",
    "print('Saved: ' + fname)\n",
    "fname = os.path.join(outputfolder, 'RPFS_Cmax_CCG_all_results.pkl.gz')\n",
    "df.to_pickle(fname)\n",
    "print('Saved: ' + fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index().info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-rccp_cronos] *",
   "language": "python",
   "name": "conda-env-.conda-rccp_cronos-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
